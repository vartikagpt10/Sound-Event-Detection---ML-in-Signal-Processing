{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLSP Project - Final",
      "provenance": [],
      "collapsed_sections": [
        "jHPXQikr260m"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vartikagpt10/Sound-Event-Detection---ML-in-Signal-Processing/blob/main/MLSP_Project_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHPXQikr260m"
      },
      "source": [
        "##Data Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVK-D80y75K2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad9b59ca-9d7b-4417-8ca0-2d75c207d8e0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHdsLuiz00IG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1df37d4-760d-4ae5-9a06-331f0f9c94e8"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "import librosa\n",
        "import pdb\n",
        "import string\n",
        "import os\n",
        "\n",
        "!pip install python-levenshtein\n",
        "\n",
        "from Levenshtein import distance"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-levenshtein in /usr/local/lib/python3.6/dist-packages (0.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from python-levenshtein) (50.3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nLSt19I283p"
      },
      "source": [
        "def wav2feat(wavfile):\n",
        "    '''\n",
        "    Input: audio wav file name\n",
        "    Output: Magnitude spectrogram\n",
        "    '''\n",
        "    x, Fs = librosa.load(wavfile, sr=44100, mono=True) \n",
        "    hop = int(0.01 * Fs) # 10ms\n",
        "    win = int(0.02 * Fs) # 20ms\n",
        "    X = librosa.stft(x, n_fft=1024, hop_length=hop, win_length=win, window='hann', center=True, pad_mode='reflect')\n",
        "    return np.abs(X)\n",
        "\n",
        "def wavs2feat(wavfiles):\n",
        "    '''\n",
        "    Concatenate the audio files listed in wavfiles\n",
        "    Input: list of audio wav file names\n",
        "    Output: Magnitude spectrogram of concatenated wav\n",
        "    '''\n",
        "    x = []\n",
        "    for wf in wavfiles:\n",
        "        x1, Fs = librosa.load(wf, sr=44100, mono=True)\n",
        "        x.append(x1)\n",
        "    x = np.hstack(x)\n",
        "    hop = int(0.01 * Fs) # 10ms\n",
        "    win = int(0.02 * Fs) # 20ms\n",
        "    X = librosa.stft(x, n_fft=1024, hop_length=hop, win_length=win, window='hann', center=True, pad_mode='reflect')\n",
        "    return np.abs(X)\n",
        "\n",
        "def read_csv(filename):\n",
        "    id_label = {}\n",
        "    with open(filename,'r') as fid:\n",
        "        for line in fid: # '176787-5-0-27.wav,engine_idling\\n'\n",
        "            tokens = line.strip().split(',') # ['176787-5-0-27.wav', 'engine_idling']\n",
        "            id_label[tokens[0]] = tokens[1]\n",
        "    return id_label\n",
        "\n",
        "def editDistance(gt, est):\n",
        "    '''both are lists of labels\n",
        "    E.g. gt is \"dog_bark-street_music-engine_idling\"\n",
        "    E.g. est is \"street_music-engine_idling\"\n",
        "    '''\n",
        "    gttokens = gt.split('-')\n",
        "    esttokens = est.split('-')\n",
        "    # Map token to char\n",
        "    tokenset = list(set(gttokens+esttokens)) # ['dog_bark', 'siren', 'street_music', 'engine_idling']\n",
        "    token_char = {}\n",
        "    for i in range(len(tokenset)):\n",
        "        token_char[tokenset[i]] = string.ascii_uppercase[i]  # {'dog_bark': 'A', 'siren': 'B', 'street_music': 'C', 'engine_idling': 'D'}\n",
        "    # convert gt and est to strings\n",
        "    gtstr = [token_char[t] for t in gttokens]\n",
        "    gtstr = ''.join(gtstr)  # 'BCA'\n",
        "    eststr = [token_char[t] for t in esttokens]\n",
        "    eststr = ''.join(eststr)  # \n",
        "    # Compare\n",
        "    editdist = distance(gtstr, eststr) # 1\n",
        "    score = 1 - editdist/len(gtstr)\n",
        "    return editdist, score\n",
        "\n",
        "def evals(gtcsv, estcsv, taskid):\n",
        "    gt_id_label = read_csv(gtcsv)\n",
        "    est_id_label = read_csv(estcsv)\n",
        "    score = 0\n",
        "    for id in est_id_label:\n",
        "        if taskid==1:\n",
        "            if est_id_label[id] == gt_id_label[id]:\n",
        "                score += 1\n",
        "        elif taskid==2:\n",
        "            _, ss = editDistance(gt_id_label[id], est_id_label[id])\n",
        "            score += ss\n",
        "        else:\n",
        "            pdb.set_trace()\n",
        "            assert False, [\"taskid not correct; it is\", taskid]\n",
        "    avgScore = score/len(est_id_label)\n",
        "    return avgScore\n",
        "\n",
        "# if __name__==\"__main__\":\n",
        "    # wavs = ['../shared_train/audio_train/180937-7-3-27.wav']\n",
        "    # wavs = ['/content/drive/MyDrive/Training data/audio_train/100652-3-0-0.wav']\n",
        "    # print(wavs2feat(wavs).shape)\n",
        "    # wavfiles = ['../shared_train/audio_train/180937-7-3-27.wav','../shared_train/audio_train/180937-7-3-27.wav']\n",
        "    # X = wavs2feat(wavs)\n",
        "    # eval('test_task1/labels.csv', 'test_task1/est.csv', 1)\n",
        "    # editDistance(\"dog_bark-street_music-engine_idling\",\"siren-street_music-engine_idling\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4CDWIbrv2xb"
      },
      "source": [
        "#**TASK1**\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXTjpGOk29Pa"
      },
      "source": [
        "##Data Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4h72Q72_8GPO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abb66ac5-79f5-44ef-bc0f-cb616de7a4e5"
      },
      "source": [
        "root = '/content/drive/MyDrive/Project/MLSP Course Project/audio_train_1ch/'\n",
        "df = pd.read_csv('/content/drive/MyDrive/Project/MLSP Course Project/labels_train.csv')\n",
        "#root = '/content/drive/MyDrive/Training data/audio_train_1ch/'\n",
        "#df = pd.read_csv('/content/drive/MyDrive/Training data/labels_train.csv')\n",
        "   \n",
        "i = 0 \n",
        "hyphen = '-'\n",
        "train_subarray0, train_subarray1, train_subarray2, train_subarray3, train_subarray4, train_subarray5, train_subarray6, train_subarray7, train_subarray8, train_subarray9 = [],[],[],[],[],[],[],[],[],[]\n",
        "train_subarray = [train_subarray0, train_subarray1, train_subarray2, train_subarray3, \n",
        "                  train_subarray4, train_subarray5, train_subarray6, train_subarray7, train_subarray8, train_subarray9] #stores the spectrograms of each class separately\n",
        "for file in df.slice_file_name:\n",
        "  j = df['slice_file_name'][i][df['slice_file_name'][i].find(hyphen) +1] # dataset separated into its classes using the file name \n",
        "  j = int(j)\n",
        "  if file.endswith(\".wav\"):\n",
        "    sample = wav2feat(root + file) \n",
        "    concan = np.zeros((513,401-sample.shape[1])) #adding zeros to make all the entries of the spectogram of the same dimension\n",
        "    sample = np.concatenate((sample, concan), axis=1)\n",
        "    print(i) #to keep track of number of files extracted\n",
        "    i = i+1\n",
        "    train_subarray[j].append(sample)\n",
        "train_subarray = np.array(train_subarray)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "291\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "296\n",
            "297\n",
            "298\n",
            "299\n",
            "300\n",
            "301\n",
            "302\n",
            "303\n",
            "304\n",
            "305\n",
            "306\n",
            "307\n",
            "308\n",
            "309\n",
            "310\n",
            "311\n",
            "312\n",
            "313\n",
            "314\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "320\n",
            "321\n",
            "322\n",
            "323\n",
            "324\n",
            "325\n",
            "326\n",
            "327\n",
            "328\n",
            "329\n",
            "330\n",
            "331\n",
            "332\n",
            "333\n",
            "334\n",
            "335\n",
            "336\n",
            "337\n",
            "338\n",
            "339\n",
            "340\n",
            "341\n",
            "342\n",
            "343\n",
            "344\n",
            "345\n",
            "346\n",
            "347\n",
            "348\n",
            "349\n",
            "350\n",
            "351\n",
            "352\n",
            "353\n",
            "354\n",
            "355\n",
            "356\n",
            "357\n",
            "358\n",
            "359\n",
            "360\n",
            "361\n",
            "362\n",
            "363\n",
            "364\n",
            "365\n",
            "366\n",
            "367\n",
            "368\n",
            "369\n",
            "370\n",
            "371\n",
            "372\n",
            "373\n",
            "374\n",
            "375\n",
            "376\n",
            "377\n",
            "378\n",
            "379\n",
            "380\n",
            "381\n",
            "382\n",
            "383\n",
            "384\n",
            "385\n",
            "386\n",
            "387\n",
            "388\n",
            "389\n",
            "390\n",
            "391\n",
            "392\n",
            "393\n",
            "394\n",
            "395\n",
            "396\n",
            "397\n",
            "398\n",
            "399\n",
            "400\n",
            "401\n",
            "402\n",
            "403\n",
            "404\n",
            "405\n",
            "406\n",
            "407\n",
            "408\n",
            "409\n",
            "410\n",
            "411\n",
            "412\n",
            "413\n",
            "414\n",
            "415\n",
            "416\n",
            "417\n",
            "418\n",
            "419\n",
            "420\n",
            "421\n",
            "422\n",
            "423\n",
            "424\n",
            "425\n",
            "426\n",
            "427\n",
            "428\n",
            "429\n",
            "430\n",
            "431\n",
            "432\n",
            "433\n",
            "434\n",
            "435\n",
            "436\n",
            "437\n",
            "438\n",
            "439\n",
            "440\n",
            "441\n",
            "442\n",
            "443\n",
            "444\n",
            "445\n",
            "446\n",
            "447\n",
            "448\n",
            "449\n",
            "450\n",
            "451\n",
            "452\n",
            "453\n",
            "454\n",
            "455\n",
            "456\n",
            "457\n",
            "458\n",
            "459\n",
            "460\n",
            "461\n",
            "462\n",
            "463\n",
            "464\n",
            "465\n",
            "466\n",
            "467\n",
            "468\n",
            "469\n",
            "470\n",
            "471\n",
            "472\n",
            "473\n",
            "474\n",
            "475\n",
            "476\n",
            "477\n",
            "478\n",
            "479\n",
            "480\n",
            "481\n",
            "482\n",
            "483\n",
            "484\n",
            "485\n",
            "486\n",
            "487\n",
            "488\n",
            "489\n",
            "490\n",
            "491\n",
            "492\n",
            "493\n",
            "494\n",
            "495\n",
            "496\n",
            "497\n",
            "498\n",
            "499\n",
            "500\n",
            "501\n",
            "502\n",
            "503\n",
            "504\n",
            "505\n",
            "506\n",
            "507\n",
            "508\n",
            "509\n",
            "510\n",
            "511\n",
            "512\n",
            "513\n",
            "514\n",
            "515\n",
            "516\n",
            "517\n",
            "518\n",
            "519\n",
            "520\n",
            "521\n",
            "522\n",
            "523\n",
            "524\n",
            "525\n",
            "526\n",
            "527\n",
            "528\n",
            "529\n",
            "530\n",
            "531\n",
            "532\n",
            "533\n",
            "534\n",
            "535\n",
            "536\n",
            "537\n",
            "538\n",
            "539\n",
            "540\n",
            "541\n",
            "542\n",
            "543\n",
            "544\n",
            "545\n",
            "546\n",
            "547\n",
            "548\n",
            "549\n",
            "550\n",
            "551\n",
            "552\n",
            "553\n",
            "554\n",
            "555\n",
            "556\n",
            "557\n",
            "558\n",
            "559\n",
            "560\n",
            "561\n",
            "562\n",
            "563\n",
            "564\n",
            "565\n",
            "566\n",
            "567\n",
            "568\n",
            "569\n",
            "570\n",
            "571\n",
            "572\n",
            "573\n",
            "574\n",
            "575\n",
            "576\n",
            "577\n",
            "578\n",
            "579\n",
            "580\n",
            "581\n",
            "582\n",
            "583\n",
            "584\n",
            "585\n",
            "586\n",
            "587\n",
            "588\n",
            "589\n",
            "590\n",
            "591\n",
            "592\n",
            "593\n",
            "594\n",
            "595\n",
            "596\n",
            "597\n",
            "598\n",
            "599\n",
            "600\n",
            "601\n",
            "602\n",
            "603\n",
            "604\n",
            "605\n",
            "606\n",
            "607\n",
            "608\n",
            "609\n",
            "610\n",
            "611\n",
            "612\n",
            "613\n",
            "614\n",
            "615\n",
            "616\n",
            "617\n",
            "618\n",
            "619\n",
            "620\n",
            "621\n",
            "622\n",
            "623\n",
            "624\n",
            "625\n",
            "626\n",
            "627\n",
            "628\n",
            "629\n",
            "630\n",
            "631\n",
            "632\n",
            "633\n",
            "634\n",
            "635\n",
            "636\n",
            "637\n",
            "638\n",
            "639\n",
            "640\n",
            "641\n",
            "642\n",
            "643\n",
            "644\n",
            "645\n",
            "646\n",
            "647\n",
            "648\n",
            "649\n",
            "650\n",
            "651\n",
            "652\n",
            "653\n",
            "654\n",
            "655\n",
            "656\n",
            "657\n",
            "658\n",
            "659\n",
            "660\n",
            "661\n",
            "662\n",
            "663\n",
            "664\n",
            "665\n",
            "666\n",
            "667\n",
            "668\n",
            "669\n",
            "670\n",
            "671\n",
            "672\n",
            "673\n",
            "674\n",
            "675\n",
            "676\n",
            "677\n",
            "678\n",
            "679\n",
            "680\n",
            "681\n",
            "682\n",
            "683\n",
            "684\n",
            "685\n",
            "686\n",
            "687\n",
            "688\n",
            "689\n",
            "690\n",
            "691\n",
            "692\n",
            "693\n",
            "694\n",
            "695\n",
            "696\n",
            "697\n",
            "698\n",
            "699\n",
            "700\n",
            "701\n",
            "702\n",
            "703\n",
            "704\n",
            "705\n",
            "706\n",
            "707\n",
            "708\n",
            "709\n",
            "710\n",
            "711\n",
            "712\n",
            "713\n",
            "714\n",
            "715\n",
            "716\n",
            "717\n",
            "718\n",
            "719\n",
            "720\n",
            "721\n",
            "722\n",
            "723\n",
            "724\n",
            "725\n",
            "726\n",
            "727\n",
            "728\n",
            "729\n",
            "730\n",
            "731\n",
            "732\n",
            "733\n",
            "734\n",
            "735\n",
            "736\n",
            "737\n",
            "738\n",
            "739\n",
            "740\n",
            "741\n",
            "742\n",
            "743\n",
            "744\n",
            "745\n",
            "746\n",
            "747\n",
            "748\n",
            "749\n",
            "750\n",
            "751\n",
            "752\n",
            "753\n",
            "754\n",
            "755\n",
            "756\n",
            "757\n",
            "758\n",
            "759\n",
            "760\n",
            "761\n",
            "762\n",
            "763\n",
            "764\n",
            "765\n",
            "766\n",
            "767\n",
            "768\n",
            "769\n",
            "770\n",
            "771\n",
            "772\n",
            "773\n",
            "774\n",
            "775\n",
            "776\n",
            "777\n",
            "778\n",
            "779\n",
            "780\n",
            "781\n",
            "782\n",
            "783\n",
            "784\n",
            "785\n",
            "786\n",
            "787\n",
            "788\n",
            "789\n",
            "790\n",
            "791\n",
            "792\n",
            "793\n",
            "794\n",
            "795\n",
            "796\n",
            "797\n",
            "798\n",
            "799\n",
            "800\n",
            "801\n",
            "802\n",
            "803\n",
            "804\n",
            "805\n",
            "806\n",
            "807\n",
            "808\n",
            "809\n",
            "810\n",
            "811\n",
            "812\n",
            "813\n",
            "814\n",
            "815\n",
            "816\n",
            "817\n",
            "818\n",
            "819\n",
            "820\n",
            "821\n",
            "822\n",
            "823\n",
            "824\n",
            "825\n",
            "826\n",
            "827\n",
            "828\n",
            "829\n",
            "830\n",
            "831\n",
            "832\n",
            "833\n",
            "834\n",
            "835\n",
            "836\n",
            "837\n",
            "838\n",
            "839\n",
            "840\n",
            "841\n",
            "842\n",
            "843\n",
            "844\n",
            "845\n",
            "846\n",
            "847\n",
            "848\n",
            "849\n",
            "850\n",
            "851\n",
            "852\n",
            "853\n",
            "854\n",
            "855\n",
            "856\n",
            "857\n",
            "858\n",
            "859\n",
            "860\n",
            "861\n",
            "862\n",
            "863\n",
            "864\n",
            "865\n",
            "866\n",
            "867\n",
            "868\n",
            "869\n",
            "870\n",
            "871\n",
            "872\n",
            "873\n",
            "874\n",
            "875\n",
            "876\n",
            "877\n",
            "878\n",
            "879\n",
            "880\n",
            "881\n",
            "882\n",
            "883\n",
            "884\n",
            "885\n",
            "886\n",
            "887\n",
            "888\n",
            "889\n",
            "890\n",
            "891\n",
            "892\n",
            "893\n",
            "894\n",
            "895\n",
            "896\n",
            "897\n",
            "898\n",
            "899\n",
            "900\n",
            "901\n",
            "902\n",
            "903\n",
            "904\n",
            "905\n",
            "906\n",
            "907\n",
            "908\n",
            "909\n",
            "910\n",
            "911\n",
            "912\n",
            "913\n",
            "914\n",
            "915\n",
            "916\n",
            "917\n",
            "918\n",
            "919\n",
            "920\n",
            "921\n",
            "922\n",
            "923\n",
            "924\n",
            "925\n",
            "926\n",
            "927\n",
            "928\n",
            "929\n",
            "930\n",
            "931\n",
            "932\n",
            "933\n",
            "934\n",
            "935\n",
            "936\n",
            "937\n",
            "938\n",
            "939\n",
            "940\n",
            "941\n",
            "942\n",
            "943\n",
            "944\n",
            "945\n",
            "946\n",
            "947\n",
            "948\n",
            "949\n",
            "950\n",
            "951\n",
            "952\n",
            "953\n",
            "954\n",
            "955\n",
            "956\n",
            "957\n",
            "958\n",
            "959\n",
            "960\n",
            "961\n",
            "962\n",
            "963\n",
            "964\n",
            "965\n",
            "966\n",
            "967\n",
            "968\n",
            "969\n",
            "970\n",
            "971\n",
            "972\n",
            "973\n",
            "974\n",
            "975\n",
            "976\n",
            "977\n",
            "978\n",
            "979\n",
            "980\n",
            "981\n",
            "982\n",
            "983\n",
            "984\n",
            "985\n",
            "986\n",
            "987\n",
            "988\n",
            "989\n",
            "990\n",
            "991\n",
            "992\n",
            "993\n",
            "994\n",
            "995\n",
            "996\n",
            "997\n",
            "998\n",
            "999\n",
            "1000\n",
            "1001\n",
            "1002\n",
            "1003\n",
            "1004\n",
            "1005\n",
            "1006\n",
            "1007\n",
            "1008\n",
            "1009\n",
            "1010\n",
            "1011\n",
            "1012\n",
            "1013\n",
            "1014\n",
            "1015\n",
            "1016\n",
            "1017\n",
            "1018\n",
            "1019\n",
            "1020\n",
            "1021\n",
            "1022\n",
            "1023\n",
            "1024\n",
            "1025\n",
            "1026\n",
            "1027\n",
            "1028\n",
            "1029\n",
            "1030\n",
            "1031\n",
            "1032\n",
            "1033\n",
            "1034\n",
            "1035\n",
            "1036\n",
            "1037\n",
            "1038\n",
            "1039\n",
            "1040\n",
            "1041\n",
            "1042\n",
            "1043\n",
            "1044\n",
            "1045\n",
            "1046\n",
            "1047\n",
            "1048\n",
            "1049\n",
            "1050\n",
            "1051\n",
            "1052\n",
            "1053\n",
            "1054\n",
            "1055\n",
            "1056\n",
            "1057\n",
            "1058\n",
            "1059\n",
            "1060\n",
            "1061\n",
            "1062\n",
            "1063\n",
            "1064\n",
            "1065\n",
            "1066\n",
            "1067\n",
            "1068\n",
            "1069\n",
            "1070\n",
            "1071\n",
            "1072\n",
            "1073\n",
            "1074\n",
            "1075\n",
            "1076\n",
            "1077\n",
            "1078\n",
            "1079\n",
            "1080\n",
            "1081\n",
            "1082\n",
            "1083\n",
            "1084\n",
            "1085\n",
            "1086\n",
            "1087\n",
            "1088\n",
            "1089\n",
            "1090\n",
            "1091\n",
            "1092\n",
            "1093\n",
            "1094\n",
            "1095\n",
            "1096\n",
            "1097\n",
            "1098\n",
            "1099\n",
            "1100\n",
            "1101\n",
            "1102\n",
            "1103\n",
            "1104\n",
            "1105\n",
            "1106\n",
            "1107\n",
            "1108\n",
            "1109\n",
            "1110\n",
            "1111\n",
            "1112\n",
            "1113\n",
            "1114\n",
            "1115\n",
            "1116\n",
            "1117\n",
            "1118\n",
            "1119\n",
            "1120\n",
            "1121\n",
            "1122\n",
            "1123\n",
            "1124\n",
            "1125\n",
            "1126\n",
            "1127\n",
            "1128\n",
            "1129\n",
            "1130\n",
            "1131\n",
            "1132\n",
            "1133\n",
            "1134\n",
            "1135\n",
            "1136\n",
            "1137\n",
            "1138\n",
            "1139\n",
            "1140\n",
            "1141\n",
            "1142\n",
            "1143\n",
            "1144\n",
            "1145\n",
            "1146\n",
            "1147\n",
            "1148\n",
            "1149\n",
            "1150\n",
            "1151\n",
            "1152\n",
            "1153\n",
            "1154\n",
            "1155\n",
            "1156\n",
            "1157\n",
            "1158\n",
            "1159\n",
            "1160\n",
            "1161\n",
            "1162\n",
            "1163\n",
            "1164\n",
            "1165\n",
            "1166\n",
            "1167\n",
            "1168\n",
            "1169\n",
            "1170\n",
            "1171\n",
            "1172\n",
            "1173\n",
            "1174\n",
            "1175\n",
            "1176\n",
            "1177\n",
            "1178\n",
            "1179\n",
            "1180\n",
            "1181\n",
            "1182\n",
            "1183\n",
            "1184\n",
            "1185\n",
            "1186\n",
            "1187\n",
            "1188\n",
            "1189\n",
            "1190\n",
            "1191\n",
            "1192\n",
            "1193\n",
            "1194\n",
            "1195\n",
            "1196\n",
            "1197\n",
            "1198\n",
            "1199\n",
            "1200\n",
            "1201\n",
            "1202\n",
            "1203\n",
            "1204\n",
            "1205\n",
            "1206\n",
            "1207\n",
            "1208\n",
            "1209\n",
            "1210\n",
            "1211\n",
            "1212\n",
            "1213\n",
            "1214\n",
            "1215\n",
            "1216\n",
            "1217\n",
            "1218\n",
            "1219\n",
            "1220\n",
            "1221\n",
            "1222\n",
            "1223\n",
            "1224\n",
            "1225\n",
            "1226\n",
            "1227\n",
            "1228\n",
            "1229\n",
            "1230\n",
            "1231\n",
            "1232\n",
            "1233\n",
            "1234\n",
            "1235\n",
            "1236\n",
            "1237\n",
            "1238\n",
            "1239\n",
            "1240\n",
            "1241\n",
            "1242\n",
            "1243\n",
            "1244\n",
            "1245\n",
            "1246\n",
            "1247\n",
            "1248\n",
            "1249\n",
            "1250\n",
            "1251\n",
            "1252\n",
            "1253\n",
            "1254\n",
            "1255\n",
            "1256\n",
            "1257\n",
            "1258\n",
            "1259\n",
            "1260\n",
            "1261\n",
            "1262\n",
            "1263\n",
            "1264\n",
            "1265\n",
            "1266\n",
            "1267\n",
            "1268\n",
            "1269\n",
            "1270\n",
            "1271\n",
            "1272\n",
            "1273\n",
            "1274\n",
            "1275\n",
            "1276\n",
            "1277\n",
            "1278\n",
            "1279\n",
            "1280\n",
            "1281\n",
            "1282\n",
            "1283\n",
            "1284\n",
            "1285\n",
            "1286\n",
            "1287\n",
            "1288\n",
            "1289\n",
            "1290\n",
            "1291\n",
            "1292\n",
            "1293\n",
            "1294\n",
            "1295\n",
            "1296\n",
            "1297\n",
            "1298\n",
            "1299\n",
            "1300\n",
            "1301\n",
            "1302\n",
            "1303\n",
            "1304\n",
            "1305\n",
            "1306\n",
            "1307\n",
            "1308\n",
            "1309\n",
            "1310\n",
            "1311\n",
            "1312\n",
            "1313\n",
            "1314\n",
            "1315\n",
            "1316\n",
            "1317\n",
            "1318\n",
            "1319\n",
            "1320\n",
            "1321\n",
            "1322\n",
            "1323\n",
            "1324\n",
            "1325\n",
            "1326\n",
            "1327\n",
            "1328\n",
            "1329\n",
            "1330\n",
            "1331\n",
            "1332\n",
            "1333\n",
            "1334\n",
            "1335\n",
            "1336\n",
            "1337\n",
            "1338\n",
            "1339\n",
            "1340\n",
            "1341\n",
            "1342\n",
            "1343\n",
            "1344\n",
            "1345\n",
            "1346\n",
            "1347\n",
            "1348\n",
            "1349\n",
            "1350\n",
            "1351\n",
            "1352\n",
            "1353\n",
            "1354\n",
            "1355\n",
            "1356\n",
            "1357\n",
            "1358\n",
            "1359\n",
            "1360\n",
            "1361\n",
            "1362\n",
            "1363\n",
            "1364\n",
            "1365\n",
            "1366\n",
            "1367\n",
            "1368\n",
            "1369\n",
            "1370\n",
            "1371\n",
            "1372\n",
            "1373\n",
            "1374\n",
            "1375\n",
            "1376\n",
            "1377\n",
            "1378\n",
            "1379\n",
            "1380\n",
            "1381\n",
            "1382\n",
            "1383\n",
            "1384\n",
            "1385\n",
            "1386\n",
            "1387\n",
            "1388\n",
            "1389\n",
            "1390\n",
            "1391\n",
            "1392\n",
            "1393\n",
            "1394\n",
            "1395\n",
            "1396\n",
            "1397\n",
            "1398\n",
            "1399\n",
            "1400\n",
            "1401\n",
            "1402\n",
            "1403\n",
            "1404\n",
            "1405\n",
            "1406\n",
            "1407\n",
            "1408\n",
            "1409\n",
            "1410\n",
            "1411\n",
            "1412\n",
            "1413\n",
            "1414\n",
            "1415\n",
            "1416\n",
            "1417\n",
            "1418\n",
            "1419\n",
            "1420\n",
            "1421\n",
            "1422\n",
            "1423\n",
            "1424\n",
            "1425\n",
            "1426\n",
            "1427\n",
            "1428\n",
            "1429\n",
            "1430\n",
            "1431\n",
            "1432\n",
            "1433\n",
            "1434\n",
            "1435\n",
            "1436\n",
            "1437\n",
            "1438\n",
            "1439\n",
            "1440\n",
            "1441\n",
            "1442\n",
            "1443\n",
            "1444\n",
            "1445\n",
            "1446\n",
            "1447\n",
            "1448\n",
            "1449\n",
            "1450\n",
            "1451\n",
            "1452\n",
            "1453\n",
            "1454\n",
            "1455\n",
            "1456\n",
            "1457\n",
            "1458\n",
            "1459\n",
            "1460\n",
            "1461\n",
            "1462\n",
            "1463\n",
            "1464\n",
            "1465\n",
            "1466\n",
            "1467\n",
            "1468\n",
            "1469\n",
            "1470\n",
            "1471\n",
            "1472\n",
            "1473\n",
            "1474\n",
            "1475\n",
            "1476\n",
            "1477\n",
            "1478\n",
            "1479\n",
            "1480\n",
            "1481\n",
            "1482\n",
            "1483\n",
            "1484\n",
            "1485\n",
            "1486\n",
            "1487\n",
            "1488\n",
            "1489\n",
            "1490\n",
            "1491\n",
            "1492\n",
            "1493\n",
            "1494\n",
            "1495\n",
            "1496\n",
            "1497\n",
            "1498\n",
            "1499\n",
            "1500\n",
            "1501\n",
            "1502\n",
            "1503\n",
            "1504\n",
            "1505\n",
            "1506\n",
            "1507\n",
            "1508\n",
            "1509\n",
            "1510\n",
            "1511\n",
            "1512\n",
            "1513\n",
            "1514\n",
            "1515\n",
            "1516\n",
            "1517\n",
            "1518\n",
            "1519\n",
            "1520\n",
            "1521\n",
            "1522\n",
            "1523\n",
            "1524\n",
            "1525\n",
            "1526\n",
            "1527\n",
            "1528\n",
            "1529\n",
            "1530\n",
            "1531\n",
            "1532\n",
            "1533\n",
            "1534\n",
            "1535\n",
            "1536\n",
            "1537\n",
            "1538\n",
            "1539\n",
            "1540\n",
            "1541\n",
            "1542\n",
            "1543\n",
            "1544\n",
            "1545\n",
            "1546\n",
            "1547\n",
            "1548\n",
            "1549\n",
            "1550\n",
            "1551\n",
            "1552\n",
            "1553\n",
            "1554\n",
            "1555\n",
            "1556\n",
            "1557\n",
            "1558\n",
            "1559\n",
            "1560\n",
            "1561\n",
            "1562\n",
            "1563\n",
            "1564\n",
            "1565\n",
            "1566\n",
            "1567\n",
            "1568\n",
            "1569\n",
            "1570\n",
            "1571\n",
            "1572\n",
            "1573\n",
            "1574\n",
            "1575\n",
            "1576\n",
            "1577\n",
            "1578\n",
            "1579\n",
            "1580\n",
            "1581\n",
            "1582\n",
            "1583\n",
            "1584\n",
            "1585\n",
            "1586\n",
            "1587\n",
            "1588\n",
            "1589\n",
            "1590\n",
            "1591\n",
            "1592\n",
            "1593\n",
            "1594\n",
            "1595\n",
            "1596\n",
            "1597\n",
            "1598\n",
            "1599\n",
            "1600\n",
            "1601\n",
            "1602\n",
            "1603\n",
            "1604\n",
            "1605\n",
            "1606\n",
            "1607\n",
            "1608\n",
            "1609\n",
            "1610\n",
            "1611\n",
            "1612\n",
            "1613\n",
            "1614\n",
            "1615\n",
            "1616\n",
            "1617\n",
            "1618\n",
            "1619\n",
            "1620\n",
            "1621\n",
            "1622\n",
            "1623\n",
            "1624\n",
            "1625\n",
            "1626\n",
            "1627\n",
            "1628\n",
            "1629\n",
            "1630\n",
            "1631\n",
            "1632\n",
            "1633\n",
            "1634\n",
            "1635\n",
            "1636\n",
            "1637\n",
            "1638\n",
            "1639\n",
            "1640\n",
            "1641\n",
            "1642\n",
            "1643\n",
            "1644\n",
            "1645\n",
            "1646\n",
            "1647\n",
            "1648\n",
            "1649\n",
            "1650\n",
            "1651\n",
            "1652\n",
            "1653\n",
            "1654\n",
            "1655\n",
            "1656\n",
            "1657\n",
            "1658\n",
            "1659\n",
            "1660\n",
            "1661\n",
            "1662\n",
            "1663\n",
            "1664\n",
            "1665\n",
            "1666\n",
            "1667\n",
            "1668\n",
            "1669\n",
            "1670\n",
            "1671\n",
            "1672\n",
            "1673\n",
            "1674\n",
            "1675\n",
            "1676\n",
            "1677\n",
            "1678\n",
            "1679\n",
            "1680\n",
            "1681\n",
            "1682\n",
            "1683\n",
            "1684\n",
            "1685\n",
            "1686\n",
            "1687\n",
            "1688\n",
            "1689\n",
            "1690\n",
            "1691\n",
            "1692\n",
            "1693\n",
            "1694\n",
            "1695\n",
            "1696\n",
            "1697\n",
            "1698\n",
            "1699\n",
            "1700\n",
            "1701\n",
            "1702\n",
            "1703\n",
            "1704\n",
            "1705\n",
            "1706\n",
            "1707\n",
            "1708\n",
            "1709\n",
            "1710\n",
            "1711\n",
            "1712\n",
            "1713\n",
            "1714\n",
            "1715\n",
            "1716\n",
            "1717\n",
            "1718\n",
            "1719\n",
            "1720\n",
            "1721\n",
            "1722\n",
            "1723\n",
            "1724\n",
            "1725\n",
            "1726\n",
            "1727\n",
            "1728\n",
            "1729\n",
            "1730\n",
            "1731\n",
            "1732\n",
            "1733\n",
            "1734\n",
            "1735\n",
            "1736\n",
            "1737\n",
            "1738\n",
            "1739\n",
            "1740\n",
            "1741\n",
            "1742\n",
            "1743\n",
            "1744\n",
            "1745\n",
            "1746\n",
            "1747\n",
            "1748\n",
            "1749\n",
            "1750\n",
            "1751\n",
            "1752\n",
            "1753\n",
            "1754\n",
            "1755\n",
            "1756\n",
            "1757\n",
            "1758\n",
            "1759\n",
            "1760\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgZfmQaFBHQO"
      },
      "source": [
        "## Data Set Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeqpRRCH-v1c"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9ZOtqsIg1_x"
      },
      "source": [
        "train_array, val_array = [[]], [[]]\r\n",
        "for i in range(10):\r\n",
        "  len_to_split = len(train_subarray[i]) \r\n",
        "  len_train = int(0.8 * len_to_split)\r\n",
        "  for j in range(len_to_split):\r\n",
        "    tup = [train_subarray[i][j],i]\r\n",
        "    if j < len_train:\r\n",
        "      train_array.append(tup)\r\n",
        "    else:\r\n",
        "      val_array.append(tup)\r\n",
        "\r\n",
        "train_array = np.array(train_array)\r\n",
        "val_array = np.array(val_array)\r\n",
        "\r\n",
        "#Remove the empty entry from each array\r\n",
        "train_array = np.delete(train_array,0)\r\n",
        "val_array = np.delete(val_array,0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xzmFjsxhACT"
      },
      "source": [
        "train_array = shuffle(train_array)\r\n",
        "val_array = shuffle(val_array)\r\n",
        "\r\n",
        "X_data = [] #stores the training spectrograms\r\n",
        "Y_data = []\r\n",
        "for i in range(len(train_array)):\r\n",
        "  X_data.append(train_array[i][0])\r\n",
        "  Y_data.append(train_array[i][1])\r\n",
        "X_data = np.array(X_data)\r\n",
        "Y_data = np.hstack(Y_data)\r\n",
        "Y_data = Y_data.reshape(Y_data.size,1)\r\n",
        "\r\n",
        "X_data1 = [] #stores the validation spectrograms\r\n",
        "Y_data1 = []\r\n",
        "for i in range(len(val_array)):\r\n",
        "  X_data1.append(val_array[i][0])\r\n",
        "  Y_data1.append(val_array[i][1])\r\n",
        "X_data1 = np.array(X_data1)\r\n",
        "Y_data1 = np.hstack(Y_data1)\r\n",
        "Y_data1 = Y_data1.reshape(Y_data1.size,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5ky9kE_hCZM"
      },
      "source": [
        "X_train = X_data.reshape(X_data.shape[0], 513, 401,1)\r\n",
        "X_val = X_data1.reshape(X_data1.shape[0], 513, 401,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1s-PuUDhETA"
      },
      "source": [
        "#one hot encoding\r\n",
        "Y_train = to_categorical(Y_data)\r\n",
        "Y_val = to_categorical(Y_data1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jzpe2SgE3BXz"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdI1qqIU3NMD"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, Dropout, Dense, MaxPooling2D, GlobalAveragePooling2D, LayerNormalization, Flatten\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtCG2NR03MZi"
      },
      "source": [
        "#CNN with 7 layers\n",
        "def model1():\n",
        "  inputs = keras.Input(shape = (513,401,1))\n",
        "  model1 = tf.keras.Sequential()\n",
        "  model1.add(LayerNormalization(axis=2))\n",
        "  model1.add(Conv2D(filters=16, kernel_size=3, input_shape=(513, 401, 1), activation='relu'))\n",
        "  model1.add(MaxPooling2D(pool_size=2))\n",
        "  model1.add(Dropout(0.2))\n",
        "\n",
        "  model1.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "  model1.add(MaxPooling2D(pool_size=2))\n",
        "  model1.add(Dropout(0.2))\n",
        "\n",
        "  model1.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
        "  model1.add(MaxPooling2D(pool_size=2))\n",
        "  model1.add(Dropout(0.2))\n",
        "\n",
        "  model1.add(Conv2D(filters=128, kernel_size=3, activation='relu'))\n",
        "  model1.add(MaxPooling2D(pool_size=2))\n",
        "  model1.add(Dropout(0.2))\n",
        "  model1.add(GlobalAveragePooling2D())\n",
        "\n",
        "  model1.add(Dense(10, activation='softmax'))\n",
        "  model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1UkMzk67yYt"
      },
      "source": [
        "#CNN with 4 layers\r\n",
        "def model2():\r\n",
        "  inputs = keras.Input(shape = (513,401,1))\r\n",
        "  x = LayerNormalization(axis = 2)(inputs)\r\n",
        "  x = Conv2D(8, kernel_size=(7,7), activation='relu', padding='same')(x)\r\n",
        "  x = MaxPooling2D(pool_size=(2,2), padding='same')(x)\r\n",
        "  x = Conv2D(16, kernel_size=(5,5), activation='relu', padding='same')(x)\r\n",
        "  x = MaxPooling2D(pool_size=(2,2), padding='same')(x)\r\n",
        "  x = Conv2D(16, kernel_size=(3,3), activation='relu', padding='same')(x)\r\n",
        "  x = MaxPooling2D(pool_size=(2,2), padding='same')(x)\r\n",
        "  x = Conv2D(32, kernel_size=(3,3), activation='relu', padding='same')(x)\r\n",
        "  x = MaxPooling2D(pool_size=(2,2), padding='same')(x)\r\n",
        "  x = Conv2D(32, kernel_size=(3,3), activation='relu', padding='same')(x)\r\n",
        "  x = Flatten()(x)\r\n",
        "  x = Dropout(0.2)(x)\r\n",
        "  x = Dense(64, activation='relu', activity_regularizer=tf.keras.regularizers.l2(0.001))(x)\r\n",
        "  o = Dense(10, activation='softmax')(x)\r\n",
        "  model = tf.keras.Model(inputs=inputs, outputs=o)\r\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "  return model  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_9aN8huuV0W"
      },
      "source": [
        "###DNN\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "def model4():\r\n",
        "  inputs = keras.Input(shape = (513,401,1))\r\n",
        "  model4 = Sequential()\r\n",
        "  model4.add(Flatten())\r\n",
        "  model4.add(Dropout(0.2))\r\n",
        "  model4.add(Dense(512, input_shape=(X_train.shape[0],513,401,1), activation='relu'))\r\n",
        "  model4.add(Dense(256, activation='relu'))\r\n",
        "  model4.add(Dense(128, activation='relu'))\r\n",
        "  model4.add(Dense(10, activation='softmax'))\r\n",
        "  model4.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "  return model4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DOdlQlq6ga5"
      },
      "source": [
        "'''opt = optimizers.Adam()\n",
        "model1.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "model1.fit(x=X_train, y=Y_train, validation_split = 0.2, verbose = 2, epochs = 150, shuffle = True, batch_size = 32)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62yqQYxb6xR3"
      },
      "source": [
        "#model4.fit(X_train, Y_train, epochs=50, verbose=1)\r\n",
        "#loss, accuracy= model4.evaluate(X_val, Y_val, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCRfy179BiGQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36442566-1b16-4ffa-b415-7711114c8ffe"
      },
      "source": [
        "#For using model 1\r\n",
        "model = model1()\r\n",
        "history = model.fit(x=X_train, y=Y_train, verbose = 2, epochs = 150, shuffle = True, batch_size = 32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "44/44 - 4s - loss: 2.1251 - accuracy: 0.1649\n",
            "Epoch 2/150\n",
            "44/44 - 3s - loss: 1.8165 - accuracy: 0.3504\n",
            "Epoch 3/150\n",
            "44/44 - 3s - loss: 1.5909 - accuracy: 0.4499\n",
            "Epoch 4/150\n",
            "44/44 - 3s - loss: 1.3758 - accuracy: 0.5203\n",
            "Epoch 5/150\n",
            "44/44 - 3s - loss: 1.2635 - accuracy: 0.5529\n",
            "Epoch 6/150\n",
            "44/44 - 3s - loss: 1.1187 - accuracy: 0.6162\n",
            "Epoch 7/150\n",
            "44/44 - 3s - loss: 1.0257 - accuracy: 0.6326\n",
            "Epoch 8/150\n",
            "44/44 - 3s - loss: 1.0000 - accuracy: 0.6539\n",
            "Epoch 9/150\n",
            "44/44 - 3s - loss: 0.9350 - accuracy: 0.6674\n",
            "Epoch 10/150\n",
            "44/44 - 3s - loss: 0.8892 - accuracy: 0.6866\n",
            "Epoch 11/150\n",
            "44/44 - 3s - loss: 0.8682 - accuracy: 0.7086\n",
            "Epoch 12/150\n",
            "44/44 - 3s - loss: 0.8194 - accuracy: 0.7228\n",
            "Epoch 13/150\n",
            "44/44 - 3s - loss: 0.7985 - accuracy: 0.7349\n",
            "Epoch 14/150\n",
            "44/44 - 3s - loss: 0.7401 - accuracy: 0.7520\n",
            "Epoch 15/150\n",
            "44/44 - 3s - loss: 0.7342 - accuracy: 0.7584\n",
            "Epoch 16/150\n",
            "44/44 - 3s - loss: 0.7285 - accuracy: 0.7584\n",
            "Epoch 17/150\n",
            "44/44 - 3s - loss: 0.6923 - accuracy: 0.7669\n",
            "Epoch 18/150\n",
            "44/44 - 3s - loss: 0.7194 - accuracy: 0.7783\n",
            "Epoch 19/150\n",
            "44/44 - 3s - loss: 0.6782 - accuracy: 0.7754\n",
            "Epoch 20/150\n",
            "44/44 - 3s - loss: 0.6417 - accuracy: 0.7910\n",
            "Epoch 21/150\n",
            "44/44 - 3s - loss: 0.5906 - accuracy: 0.8053\n",
            "Epoch 22/150\n",
            "44/44 - 3s - loss: 0.5805 - accuracy: 0.8181\n",
            "Epoch 23/150\n",
            "44/44 - 3s - loss: 0.5710 - accuracy: 0.8024\n",
            "Epoch 24/150\n",
            "44/44 - 3s - loss: 0.5574 - accuracy: 0.8195\n",
            "Epoch 25/150\n",
            "44/44 - 3s - loss: 0.5681 - accuracy: 0.8088\n",
            "Epoch 26/150\n",
            "44/44 - 3s - loss: 0.5304 - accuracy: 0.8237\n",
            "Epoch 27/150\n",
            "44/44 - 3s - loss: 0.5445 - accuracy: 0.8216\n",
            "Epoch 28/150\n",
            "44/44 - 3s - loss: 0.5271 - accuracy: 0.8252\n",
            "Epoch 29/150\n",
            "44/44 - 3s - loss: 0.4973 - accuracy: 0.8287\n",
            "Epoch 30/150\n",
            "44/44 - 3s - loss: 0.5232 - accuracy: 0.8266\n",
            "Epoch 31/150\n",
            "44/44 - 3s - loss: 0.4623 - accuracy: 0.8458\n",
            "Epoch 32/150\n",
            "44/44 - 3s - loss: 0.4628 - accuracy: 0.8479\n",
            "Epoch 33/150\n",
            "44/44 - 3s - loss: 0.4487 - accuracy: 0.8529\n",
            "Epoch 34/150\n",
            "44/44 - 3s - loss: 0.4232 - accuracy: 0.8564\n",
            "Epoch 35/150\n",
            "44/44 - 3s - loss: 0.4758 - accuracy: 0.8358\n",
            "Epoch 36/150\n",
            "44/44 - 3s - loss: 0.4092 - accuracy: 0.8529\n",
            "Epoch 37/150\n",
            "44/44 - 3s - loss: 0.4378 - accuracy: 0.8493\n",
            "Epoch 38/150\n",
            "44/44 - 3s - loss: 0.3568 - accuracy: 0.8756\n",
            "Epoch 39/150\n",
            "44/44 - 3s - loss: 0.3720 - accuracy: 0.8635\n",
            "Epoch 40/150\n",
            "44/44 - 3s - loss: 0.3981 - accuracy: 0.8628\n",
            "Epoch 41/150\n",
            "44/44 - 3s - loss: 0.3469 - accuracy: 0.8834\n",
            "Epoch 42/150\n",
            "44/44 - 3s - loss: 0.3297 - accuracy: 0.8863\n",
            "Epoch 43/150\n",
            "44/44 - 3s - loss: 0.3601 - accuracy: 0.8785\n",
            "Epoch 44/150\n",
            "44/44 - 3s - loss: 0.3670 - accuracy: 0.8678\n",
            "Epoch 45/150\n",
            "44/44 - 3s - loss: 0.3258 - accuracy: 0.8863\n",
            "Epoch 46/150\n",
            "44/44 - 3s - loss: 0.3095 - accuracy: 0.8998\n",
            "Epoch 47/150\n",
            "44/44 - 3s - loss: 0.2931 - accuracy: 0.9012\n",
            "Epoch 48/150\n",
            "44/44 - 3s - loss: 0.3111 - accuracy: 0.8977\n",
            "Epoch 49/150\n",
            "44/44 - 3s - loss: 0.3475 - accuracy: 0.8948\n",
            "Epoch 50/150\n",
            "44/44 - 3s - loss: 0.3586 - accuracy: 0.8778\n",
            "Epoch 51/150\n",
            "44/44 - 3s - loss: 0.3094 - accuracy: 0.8927\n",
            "Epoch 52/150\n",
            "44/44 - 3s - loss: 0.2983 - accuracy: 0.9026\n",
            "Epoch 53/150\n",
            "44/44 - 3s - loss: 0.2662 - accuracy: 0.9119\n",
            "Epoch 54/150\n",
            "44/44 - 3s - loss: 0.3151 - accuracy: 0.8934\n",
            "Epoch 55/150\n",
            "44/44 - 3s - loss: 0.2655 - accuracy: 0.9069\n",
            "Epoch 56/150\n",
            "44/44 - 3s - loss: 0.2612 - accuracy: 0.9183\n",
            "Epoch 57/150\n",
            "44/44 - 3s - loss: 0.2537 - accuracy: 0.9183\n",
            "Epoch 58/150\n",
            "44/44 - 3s - loss: 0.2390 - accuracy: 0.9176\n",
            "Epoch 59/150\n",
            "44/44 - 3s - loss: 0.2126 - accuracy: 0.9346\n",
            "Epoch 60/150\n",
            "44/44 - 3s - loss: 0.2172 - accuracy: 0.9296\n",
            "Epoch 61/150\n",
            "44/44 - 3s - loss: 0.3265 - accuracy: 0.8927\n",
            "Epoch 62/150\n",
            "44/44 - 3s - loss: 0.2034 - accuracy: 0.9382\n",
            "Epoch 63/150\n",
            "44/44 - 3s - loss: 0.2513 - accuracy: 0.9154\n",
            "Epoch 64/150\n",
            "44/44 - 3s - loss: 0.2287 - accuracy: 0.9240\n",
            "Epoch 65/150\n",
            "44/44 - 3s - loss: 0.2357 - accuracy: 0.9133\n",
            "Epoch 66/150\n",
            "44/44 - 3s - loss: 0.1905 - accuracy: 0.9339\n",
            "Epoch 67/150\n",
            "44/44 - 3s - loss: 0.2021 - accuracy: 0.9339\n",
            "Epoch 68/150\n",
            "44/44 - 3s - loss: 0.1694 - accuracy: 0.9431\n",
            "Epoch 69/150\n",
            "44/44 - 3s - loss: 0.1866 - accuracy: 0.9403\n",
            "Epoch 70/150\n",
            "44/44 - 3s - loss: 0.2360 - accuracy: 0.9197\n",
            "Epoch 71/150\n",
            "44/44 - 3s - loss: 0.2230 - accuracy: 0.9296\n",
            "Epoch 72/150\n",
            "44/44 - 3s - loss: 0.1866 - accuracy: 0.9360\n",
            "Epoch 73/150\n",
            "44/44 - 3s - loss: 0.2086 - accuracy: 0.9311\n",
            "Epoch 74/150\n",
            "44/44 - 3s - loss: 0.2026 - accuracy: 0.9318\n",
            "Epoch 75/150\n",
            "44/44 - 3s - loss: 0.1702 - accuracy: 0.9446\n",
            "Epoch 76/150\n",
            "44/44 - 3s - loss: 0.2329 - accuracy: 0.9275\n",
            "Epoch 77/150\n",
            "44/44 - 3s - loss: 0.1974 - accuracy: 0.9275\n",
            "Epoch 78/150\n",
            "44/44 - 3s - loss: 0.6172 - accuracy: 0.8593\n",
            "Epoch 79/150\n",
            "44/44 - 3s - loss: 0.2266 - accuracy: 0.9218\n",
            "Epoch 80/150\n",
            "44/44 - 3s - loss: 0.1571 - accuracy: 0.9495\n",
            "Epoch 81/150\n",
            "44/44 - 3s - loss: 0.1443 - accuracy: 0.9559\n",
            "Epoch 82/150\n",
            "44/44 - 3s - loss: 0.1460 - accuracy: 0.9488\n",
            "Epoch 83/150\n",
            "44/44 - 3s - loss: 0.1394 - accuracy: 0.9488\n",
            "Epoch 84/150\n",
            "44/44 - 3s - loss: 0.1316 - accuracy: 0.9559\n",
            "Epoch 85/150\n",
            "44/44 - 3s - loss: 0.1337 - accuracy: 0.9531\n",
            "Epoch 86/150\n",
            "44/44 - 3s - loss: 0.2064 - accuracy: 0.9332\n",
            "Epoch 87/150\n",
            "44/44 - 3s - loss: 0.1805 - accuracy: 0.9339\n",
            "Epoch 88/150\n",
            "44/44 - 3s - loss: 0.1405 - accuracy: 0.9502\n",
            "Epoch 89/150\n",
            "44/44 - 3s - loss: 0.1507 - accuracy: 0.9538\n",
            "Epoch 90/150\n",
            "44/44 - 3s - loss: 0.1565 - accuracy: 0.9488\n",
            "Epoch 91/150\n",
            "44/44 - 3s - loss: 0.2157 - accuracy: 0.9282\n",
            "Epoch 92/150\n",
            "44/44 - 3s - loss: 0.1228 - accuracy: 0.9638\n",
            "Epoch 93/150\n",
            "44/44 - 3s - loss: 0.1455 - accuracy: 0.9431\n",
            "Epoch 94/150\n",
            "44/44 - 3s - loss: 0.0998 - accuracy: 0.9687\n",
            "Epoch 95/150\n",
            "44/44 - 3s - loss: 0.1749 - accuracy: 0.9367\n",
            "Epoch 96/150\n",
            "44/44 - 3s - loss: 0.1284 - accuracy: 0.9623\n",
            "Epoch 97/150\n",
            "44/44 - 3s - loss: 0.0927 - accuracy: 0.9716\n",
            "Epoch 98/150\n",
            "44/44 - 3s - loss: 0.1509 - accuracy: 0.9453\n",
            "Epoch 99/150\n",
            "44/44 - 3s - loss: 0.1463 - accuracy: 0.9510\n",
            "Epoch 100/150\n",
            "44/44 - 3s - loss: 0.1197 - accuracy: 0.9602\n",
            "Epoch 101/150\n",
            "44/44 - 3s - loss: 0.1108 - accuracy: 0.9602\n",
            "Epoch 102/150\n",
            "44/44 - 3s - loss: 0.1343 - accuracy: 0.9566\n",
            "Epoch 103/150\n",
            "44/44 - 3s - loss: 0.0887 - accuracy: 0.9716\n",
            "Epoch 104/150\n",
            "44/44 - 3s - loss: 0.0923 - accuracy: 0.9716\n",
            "Epoch 105/150\n",
            "44/44 - 3s - loss: 0.0738 - accuracy: 0.9765\n",
            "Epoch 106/150\n",
            "44/44 - 3s - loss: 0.1983 - accuracy: 0.9403\n",
            "Epoch 107/150\n",
            "44/44 - 3s - loss: 0.2185 - accuracy: 0.9382\n",
            "Epoch 108/150\n",
            "44/44 - 3s - loss: 0.1050 - accuracy: 0.9659\n",
            "Epoch 109/150\n",
            "44/44 - 3s - loss: 0.0814 - accuracy: 0.9758\n",
            "Epoch 110/150\n",
            "44/44 - 3s - loss: 0.0966 - accuracy: 0.9680\n",
            "Epoch 111/150\n",
            "44/44 - 3s - loss: 0.0880 - accuracy: 0.9680\n",
            "Epoch 112/150\n",
            "44/44 - 3s - loss: 0.2191 - accuracy: 0.9367\n",
            "Epoch 113/150\n",
            "44/44 - 3s - loss: 0.1700 - accuracy: 0.9431\n",
            "Epoch 114/150\n",
            "44/44 - 3s - loss: 0.0992 - accuracy: 0.9687\n",
            "Epoch 115/150\n",
            "44/44 - 3s - loss: 0.0694 - accuracy: 0.9815\n",
            "Epoch 116/150\n",
            "44/44 - 3s - loss: 0.0622 - accuracy: 0.9815\n",
            "Epoch 117/150\n",
            "44/44 - 3s - loss: 0.0655 - accuracy: 0.9851\n",
            "Epoch 118/150\n",
            "44/44 - 3s - loss: 0.0929 - accuracy: 0.9638\n",
            "Epoch 119/150\n",
            "44/44 - 3s - loss: 0.1560 - accuracy: 0.9467\n",
            "Epoch 120/150\n",
            "44/44 - 3s - loss: 0.0930 - accuracy: 0.9659\n",
            "Epoch 121/150\n",
            "44/44 - 3s - loss: 0.1430 - accuracy: 0.9566\n",
            "Epoch 122/150\n",
            "44/44 - 3s - loss: 0.2486 - accuracy: 0.9197\n",
            "Epoch 123/150\n",
            "44/44 - 3s - loss: 0.1391 - accuracy: 0.9531\n",
            "Epoch 124/150\n",
            "44/44 - 3s - loss: 0.0728 - accuracy: 0.9773\n",
            "Epoch 125/150\n",
            "44/44 - 3s - loss: 0.0763 - accuracy: 0.9765\n",
            "Epoch 126/150\n",
            "44/44 - 3s - loss: 0.0994 - accuracy: 0.9652\n",
            "Epoch 127/150\n",
            "44/44 - 3s - loss: 0.0636 - accuracy: 0.9851\n",
            "Epoch 128/150\n",
            "44/44 - 3s - loss: 0.0832 - accuracy: 0.9737\n",
            "Epoch 129/150\n",
            "44/44 - 3s - loss: 0.0555 - accuracy: 0.9801\n",
            "Epoch 130/150\n",
            "44/44 - 3s - loss: 0.0467 - accuracy: 0.9858\n",
            "Epoch 131/150\n",
            "44/44 - 3s - loss: 0.0639 - accuracy: 0.9794\n",
            "Epoch 132/150\n",
            "44/44 - 3s - loss: 0.1656 - accuracy: 0.9460\n",
            "Epoch 133/150\n",
            "44/44 - 3s - loss: 0.1077 - accuracy: 0.9694\n",
            "Epoch 134/150\n",
            "44/44 - 3s - loss: 0.0476 - accuracy: 0.9879\n",
            "Epoch 135/150\n",
            "44/44 - 3s - loss: 0.0369 - accuracy: 0.9922\n",
            "Epoch 136/150\n",
            "44/44 - 3s - loss: 0.0738 - accuracy: 0.9687\n",
            "Epoch 137/150\n",
            "44/44 - 3s - loss: 0.1152 - accuracy: 0.9623\n",
            "Epoch 138/150\n",
            "44/44 - 3s - loss: 0.0863 - accuracy: 0.9687\n",
            "Epoch 139/150\n",
            "44/44 - 3s - loss: 0.0882 - accuracy: 0.9716\n",
            "Epoch 140/150\n",
            "44/44 - 3s - loss: 0.0530 - accuracy: 0.9865\n",
            "Epoch 141/150\n",
            "44/44 - 3s - loss: 0.0575 - accuracy: 0.9801\n",
            "Epoch 142/150\n",
            "44/44 - 3s - loss: 0.0633 - accuracy: 0.9794\n",
            "Epoch 143/150\n",
            "44/44 - 3s - loss: 0.1305 - accuracy: 0.9616\n",
            "Epoch 144/150\n",
            "44/44 - 3s - loss: 0.1369 - accuracy: 0.9630\n",
            "Epoch 145/150\n",
            "44/44 - 3s - loss: 0.0935 - accuracy: 0.9758\n",
            "Epoch 146/150\n",
            "44/44 - 3s - loss: 0.0664 - accuracy: 0.9773\n",
            "Epoch 147/150\n",
            "44/44 - 3s - loss: 0.0704 - accuracy: 0.9744\n",
            "Epoch 148/150\n",
            "44/44 - 3s - loss: 0.0627 - accuracy: 0.9801\n",
            "Epoch 149/150\n",
            "44/44 - 3s - loss: 0.0536 - accuracy: 0.9829\n",
            "Epoch 150/150\n",
            "44/44 - 3s - loss: 0.0421 - accuracy: 0.9872\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoallDAqEI9I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4607632a-61d9-45ca-b98b-679585d19678"
      },
      "source": [
        "model.evaluate(X_val, Y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12/12 [==============================] - 0s 27ms/step - loss: 2.4300 - accuracy: 0.6751\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.4299561977386475, 0.6751412153244019]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wShygwJZfQPM"
      },
      "source": [
        "##Voting on Different Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Sh7VxOffjlb"
      },
      "source": [
        "from sklearn.ensemble import VotingClassifier \r\n",
        "from sklearn.metrics import accuracy_score \r\n",
        "\r\n",
        "# group / ensemble of models \r\n",
        "estimator = [] \r\n",
        "estimator.append(('CNN_2', model2())) \r\n",
        "estimator.append(('DNN', model4())) \r\n",
        "estimator.append(('CNN_1', model1())) \r\n",
        "  \r\n",
        "# Voting Classifier with hard voting \r\n",
        "vot_hard = VotingClassifier(estimators = estimator, voting ='hard') \r\n",
        "vot_hard.fit(X_train, Y_train)\r\n",
        "vot_hard.evaluate(X_val, Y_val) \r\n",
        "Y_pred = vot_hard.predict(X_test) \r\n",
        "model = vot_hard\r\n",
        "\r\n",
        "print(\"Hard Voting Score % d\" % score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pgwwb4XD6-Gt"
      },
      "source": [
        "##Sample Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eOcyTCC7AbU"
      },
      "source": [
        "root1 = '/content/drive/MyDrive/Project/MLSP Course Project/sample_test_task1/feats/'\n",
        "df1 = pd.read_csv('/content/drive/MyDrive/Project/MLSP Course Project/sample_test_task1/labels.csv')\n",
        "#root1 = '/content/drive/MyDrive/Training data/sample_test_task1/feats/'\n",
        "#df1 = pd.read_csv('/content/drive/MyDrive/Training data/sample_test_task1/labels.csv')\n",
        "df1 = np.array(df1)\n",
        "test_data = []\n",
        "sample = np.load(root1 + 'a00001.npy') \n",
        "concan = np.zeros((513,401-sample.shape[1]))\n",
        "sample = np.concatenate((sample, concan), axis=1)\n",
        "test_data.append(sample)\n",
        "i = 1\n",
        "for file in df1[:,:1]:\n",
        "  sample = np.load(root1 + file[0] + '.npy') \n",
        "  concan = np.zeros((513,401-sample.shape[1]))\n",
        "  sample = np.concatenate((sample, concan), axis=1)\n",
        "  test_data.append(sample)\n",
        "  print(i)\n",
        "  i = i+1\n",
        "test_data = np.array(test_data)\n",
        "X_test = test_data.reshape(test_data.shape[0], 513, 401, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ara5YVTFffB"
      },
      "source": [
        "pred = model.predict(X_test)\r\n",
        "pred = np.argmax(pred,axis=1)\r\n",
        "\r\n",
        "enc = {'air_conditioner': 0, 'car_horn': 1, 'children_playing': 2, 'dog_bark': 3, 'drilling': 4, 'engine_idling': 5, 'gun_shot': 6, 'jackhammer': 7, 'siren': 8, 'street_music': 9}\r\n",
        "cl = list(enc.keys())\r\n",
        "la = list(enc.values())\r\n",
        " \r\n",
        "Y_pred = []         #list of predicted labels\r\n",
        "for i in range(len(pred)):\r\n",
        "  position = la.index(pred[i])\r\n",
        "  Y_pred.append(cl[position])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hF16IelU1vnb"
      },
      "source": [
        "##Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BTkSazt1xZ4"
      },
      "source": [
        "test_x=[]\r\n",
        "for i in range(1,51):\r\n",
        "  if (i<10):\r\n",
        "    path='/content/drive/MyDrive/Project/MLSP Course Project/feats/a00'+str(i)+'.npy'\r\n",
        "  else:\r\n",
        "    path='/content/drive/MyDrive/Project/MLSP Course Project/feats/a0'+str(i)+'.npy'\r\n",
        "  spect=np.load(path)\r\n",
        "  concan = np.zeros((513,401-spect.shape[1]))\r\n",
        "  sample = np.concatenate((spect, concan), axis=1)\r\n",
        "  test_x.append(sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUF9MaoG2OZj"
      },
      "source": [
        "test_x = np.array(test_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVhTa3Kb2R7V"
      },
      "source": [
        "test_x.reshape(50,513,401,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73UD_WV42JJ6"
      },
      "source": [
        "pred = model.predict(test_x)\r\n",
        "pred = np.argmax(pred,axis=1)\r\n",
        "\r\n",
        "enc = {'air_conditioner': 0, 'car_horn': 1, 'children_playing': 2, 'dog_bark': 3, 'drilling': 4, 'engine_idling': 5, 'gun_shot': 6, 'jackhammer': 7, 'siren': 8, 'street_music': 9}\r\n",
        "cl = list(enc.keys())\r\n",
        "la = list(enc.values())\r\n",
        " \r\n",
        "Y_pred = []         #list of predicted labels\r\n",
        "for i in range(len(pred)):\r\n",
        "  position = la.index(pred[i])\r\n",
        "  Y_pred.append(cl[position])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tK3kCxJK3Npt"
      },
      "source": [
        "##Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCdtcPYv29Bg",
        "outputId": "9fbba35b-a3dd-4269-8e78-cd647ac72844"
      },
      "source": [
        "Y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['air_conditioner',\n",
              " 'street_music',\n",
              " 'dog_bark',\n",
              " 'jackhammer',\n",
              " 'children_playing',\n",
              " 'car_horn',\n",
              " 'street_music',\n",
              " 'gun_shot',\n",
              " 'jackhammer',\n",
              " 'dog_bark',\n",
              " 'gun_shot',\n",
              " 'air_conditioner',\n",
              " 'children_playing',\n",
              " 'car_horn',\n",
              " 'engine_idling',\n",
              " 'siren',\n",
              " 'drilling',\n",
              " 'children_playing',\n",
              " 'drilling',\n",
              " 'car_horn',\n",
              " 'jackhammer',\n",
              " 'street_music',\n",
              " 'gun_shot',\n",
              " 'engine_idling',\n",
              " 'jackhammer',\n",
              " 'air_conditioner',\n",
              " 'air_conditioner',\n",
              " 'street_music',\n",
              " 'children_playing',\n",
              " 'children_playing',\n",
              " 'car_horn',\n",
              " 'street_music',\n",
              " 'siren',\n",
              " 'engine_idling',\n",
              " 'children_playing',\n",
              " 'drilling',\n",
              " 'dog_bark',\n",
              " 'gun_shot',\n",
              " 'engine_idling',\n",
              " 'gun_shot',\n",
              " 'drilling',\n",
              " 'drilling',\n",
              " 'drilling',\n",
              " 'jackhammer',\n",
              " 'dog_bark',\n",
              " 'children_playing',\n",
              " 'street_music',\n",
              " 'drilling',\n",
              " 'jackhammer',\n",
              " 'drilling']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lV5io22f4hpq"
      },
      "source": [
        "fname = []\r\n",
        "for i in range(1,51):\r\n",
        "  if (i<10):\r\n",
        "    temp_str='a00'+str(i)+'.npy'\r\n",
        "  else:\r\n",
        "    temp_str='a00'+str(i)+'.npy'\r\n",
        "  fname.append(temp_str)\r\n",
        "dict = {'name': fname, 'label': Y_pred}\r\n",
        "df2 = pd.DataFrame(dict)\r\n",
        "df2.to_csv('/content/drive/MyDrive/Project/MLSP Course Project/task1_labels_test.csv', header=False, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGWcW-UCwonw"
      },
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}